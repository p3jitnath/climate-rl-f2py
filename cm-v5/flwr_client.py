import sys

BASE_DIR = "/gws/nopw/j04/ai4er/users/pn341/climate-rl-f2py/cm-v5"
RL_ALGO = "ddpg"
sys.path.append(f"{BASE_DIR}/rl-algos/{RL_ALGO}")

import os
import subprocess
import sys

import f2py_climate_envs
import flwr as fl
import gymnasium as gym
import numpy as np
from ddpg_actor import Actor
from ddpg_critic import Critic
from smartredis import Client


class FlowerClient(fl.client.NumPyClient):
    def __init__(self, actor_layer_size, cid):
        super().__init__()
        self.actor_layer_size = actor_layer_size
        self.seed = self.cid = cid

        # SmartRedis setup
        self.REDIS_ADDRESS = os.getenv("SSDB")
        if self.REDIS_ADDRESS is None:
            raise EnvironmentError("SSDB environment variable is not set.")
        self.redis = Client(address=self.REDIS_ADDRESS, cluster=False)
        # print(f"Connected to Redis server: {self.REDIS_ADDRESS}")

        # print("DDPG RL Agent initiated ...", flush=True)
        cmd = f"""python -u {BASE_DIR}/rl-algos/ddpg/main.py --env_id SimpleClimateBiasCorrection-v0 --num_steps 200 """
        cmd += f"--flwr_client {self.cid} --seed {self.seed} "
        cmd += f"--actor_layer_size {self.actor_layer_size}"
        print(cmd)

        # Check if the command is already running using `pgrep`
        check_cmd = f"pgrep -f '{cmd}'"
        result = subprocess.run(
            check_cmd,
            shell=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
        )

        # If no process is found, `pgrep` returns a non-zero exit code, so we start the process
        if result.returncode != 0:
            subprocess.Popen(cmd.split())
        else:
            pass  # Process is already running

        def make_env(
            env_id, seed, idx, capture_video, run_name, capture_video_freq
        ):
            def thunk():
                if capture_video and idx == 0:
                    env = gym.make(env_id, seed=seed, render_mode="rgb_array")
                    env = gym.wrappers.RecordVideo(
                        env,
                        f"videos/{run_name}",
                        episode_trigger=lambda x: (x == 0)
                        or (
                            x % capture_video_freq == (capture_video_freq - 1)
                        ),  # add 1 to the episode count generated by gym
                    )
                else:
                    env = gym.make(env_id, seed=seed)
                env = gym.wrappers.RecordEpisodeStatistics(env)
                env.action_space.seed(seed)
                return env

            return thunk

        # 0. env setup
        self.envs = gym.vector.SyncVectorEnv(
            [
                make_env(
                    "SimpleClimateBiasCorrection-v0",
                    0,
                    0,
                    False,
                    "",
                    0,
                )
            ]
        )
        assert isinstance(
            self.envs.single_action_space, gym.spaces.Box
        ), "only continuous action space is supported"

        self.model = Actor(self.envs, self.actor_layer_size)

        # print("client initiated.", flush=True)

    def set_parameters(self, parameters):
        # print("invoked set_parameters ...", flush=True)
        # Flatten and stack all layer weights into one large tensor
        weights = np.concatenate([param.flatten() for param in parameters])

        # Store weights in Redis and send a signal to indicate update
        self.redis.put_tensor(f"actor_network_weights_s{self.seed}", weights)
        self.redis.put_tensor(
            f"SIGWEIGHTS_G2C_S{self.seed}", np.array([1], dtype=np.int32)
        )

    def get_parameters(self, config):
        # print("invoked get_parameters ...", flush=True)
        # Wait for signal that weights are available
        while not self.redis.tensor_exists(f"SIGWEIGHTS_C2G_S{self.seed}"):
            pass

        # Retrieve and reshape weights tensor based on Actor's structure
        weights = self.redis.get_tensor(f"actor_network_weights_s{self.seed}")
        parameters = []
        offset = 0
        for param in Actor(self.envs, self.actor_layer_size).parameters():
            size = np.prod(param.shape)
            layer_weights = weights[offset : offset + size].reshape(
                param.shape
            )
            parameters.append(layer_weights)
            offset += size

        # Clear weights and signal to reset for the next round
        self.redis.delete_tensor(f"actor_network_weights_s{self.seed}")
        self.redis.delete_tensor(f"SIGWEIGHTS_C2G_S{self.seed}")

        return parameters

    def fit(self, parameters, config):
        # print("invoked fit ...", flush=True)

        # Update the actor network parameters
        self.set_parameters(parameters)

        # Retrieve updated parameters from Redis after RL processing
        updated_parameters = self.get_parameters(config)

        return updated_parameters, 200, {}


def generate_client_fn(actor_layer_size=256):
    def client_fn(cid):
        # print("inside client fn ...", flush=True)
        return FlowerClient(actor_layer_size, cid)

    return client_fn
